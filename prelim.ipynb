{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f659f0-b277-46d1-bb1c-2da7e2101c1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from maraboupy import Marabou, MarabouCore\n",
    "from prettytable import PrettyTable\n",
    "import sys\n",
    "from maraboupy.MarabouNetworkONNX import MarabouNetworkONNX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c0cee2-b787-46a4-b798-72f54555fc02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#simple MLP as our model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, arch):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for i in range(len(arch) - 1):\n",
    "            layers.append(nn.Linear(arch[i], arch[i+1]))\n",
    "            if i < len(arch) - 2: \n",
    "                layers.append(nn.ReLU())\n",
    "        \n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "#subroutine to train model wholesale using Outlier Exposure with many lambda values\n",
    "def train(X_train, y_train, lams, n_epochs=100, batch_size=128):\n",
    "    models = {}\n",
    "    for lam in lams:\n",
    "        model = MLP([2,32,32,32,2])\n",
    "        \n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            for i in range(0, len(X_train), batch_size):\n",
    "                batch_X = torch.tensor(X_train[i:i + batch_size], dtype=torch.float32)\n",
    "                batch_y = torch.tensor(y_train[i:i + batch_size], dtype=torch.long)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(batch_X)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                if lam > 0:  \n",
    "                    outlier_outputs = model(torch.tensor(outliers, dtype=torch.float32))\n",
    "                    outlier_loss = lam * torch.mean(torch.sum(outlier_outputs ** 2, dim=1))\n",
    "                    loss += outlier_loss\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        models[lam] = model\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5727d7-a685-4049-af2a-cc05cb6abe35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_conf(models, X, y, lams, zoom, fname=None):\n",
    "    rows = (len(lams) + 3) // 4  \n",
    "    cols = min(len(lams), 4)     \n",
    "    fig, axs = plt.subplots(nrows=rows, ncols=cols, figsize=(5 * cols, 4 * rows), squeeze=False)\n",
    "    \n",
    "    for i, lam in enumerate(lams):\n",
    "        ax = axs[i // cols, i % cols]\n",
    "        model = models[lam]\n",
    "        x_span = np.linspace(X[:, 0].min() - zoom, X[:, 0].max() + zoom, 400)\n",
    "        y_span = np.linspace(X[:, 1].min() - zoom, X[:, 1].max() + zoom, 400)\n",
    "        xx, yy = np.meshgrid(x_span, y_span)\n",
    "        grid = torch.tensor(np.c_[xx.ravel(), yy.ravel()], dtype=torch.float32)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pred_func = model(grid)\n",
    "        \n",
    "        Z = np.argmax(pred_func.numpy(), axis=1).reshape(xx.shape)\n",
    "        conf = torch.softmax(pred_func, dim=1).numpy().max(axis=1).reshape(xx.shape)\n",
    "        \n",
    "        conf_plot = ax.contourf(xx, yy, conf, alpha=0.7, levels=np.linspace(0, 1, 50), cmap='viridis')\n",
    "        ax.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.bwr, alpha=0.7)\n",
    "        ax.set_title(f'$\\lambda = {lam}$', fontsize=14)\n",
    "        \n",
    "        cbar = fig.colorbar(conf_plot, ax=ax, ticks=np.linspace(0, 1, 11))\n",
    "    \n",
    "    for j in range(i + 1, rows * cols):\n",
    "        if i // cols < rows:\n",
    "            axs[j // cols, j % cols].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if fname is not None:\n",
    "        plt.savefig(f'{fname}.pdf', format='pdf')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419400ff-f6ec-46af-820a-9903951b2eac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X, y = make_moons(n_samples=1000, noise=0.06, random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "n_outliers = 100\n",
    "c_mus = [np.mean(X[y == k], axis=0) for k in range(2)]\n",
    "cov = np.cov(X.T)\n",
    "eps = 0.001\n",
    "\n",
    "outliers = []\n",
    "test_outliers = []\n",
    "\n",
    "for k in range(2):\n",
    "    class_outliers = []\n",
    "    test_class_outliers = []\n",
    "\n",
    "    while len(class_outliers) < n_outliers // 2:\n",
    "        outlier = np.random.multivariate_normal(c_mus[k], cov)\n",
    "        likelihood = np.exp(-0.5 * np.dot(np.dot(outlier - c_mus[k], np.linalg.inv(cov)), outlier - c_mus[k])) / (2 * np.pi * np.sqrt(np.linalg.det(cov)))\n",
    "        if likelihood < eps:\n",
    "            class_outliers.append(outlier)\n",
    "\n",
    "    test_cov = cov * 2.0 \n",
    "    while len(test_class_outliers) < n_outliers // 2:\n",
    "        test_outlier = np.random.multivariate_normal(c_mus[k], test_cov)\n",
    "        test_likelihood = np.exp(-0.5 * np.dot(np.dot(test_outlier - c_mus[k], np.linalg.inv(test_cov)), test_outlier - c_mus[k])) / (2 * np.pi * np.sqrt(np.linalg.det(test_cov)))\n",
    "        if test_likelihood < eps:\n",
    "            test_class_outliers.append(test_outlier)\n",
    "\n",
    "    outliers.extend(class_outliers)\n",
    "    test_outliers.extend(test_class_outliers)\n",
    "\n",
    "outliers = np.array(outliers)\n",
    "test_outliers = np.array(test_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e239d8-7cc5-43c1-804b-2a5ac9cd6d0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10, 4))\n",
    "\n",
    "axs[0].scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=plt.cm.bwr, alpha=0.7)\n",
    "axs[0].set_title(\"Original\")\n",
    "\n",
    "axs[1].scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=plt.cm.bwr, alpha=0.7)\n",
    "axs[1].scatter(outliers[:, 0], outliers[:, 1], color='green', marker='x', alpha=0.7)\n",
    "axs[1].scatter(test_outliers[:, 0], test_outliers[:, 1], color='orange', marker='x', alpha=0.7)\n",
    "axs[1].set_title(\"With outliers\")\n",
    "\n",
    "axs[1].legend([\"Training data\", \"Training outliers\", \"Test outliers\"], loc=\"upper right\")\n",
    "\n",
    "plt.savefig('OE.pdf', format='pdf')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a64a9ef-6553-470f-a77e-a8e44bb369d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lams = [0,0.1,0.5,1,5,10,20,50]\n",
    "models = train(X_train, y_train, lams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d747b0-c643-49f7-a194-007da5986f49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_conf(models, X_train, y_train, lams, zoom=30, fname=\"conff1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb31f2f-a50b-4170-8a01-87349d6430d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def verify_ood_rejection(model, X_OOD, tau, f):\n",
    "    results = []\n",
    "    for x in X_OOD:\n",
    "        xin = torch.tensor(x, dtype=torch.float32).unsqueeze(0)\n",
    "        onnx_f = \"model.onnx\"\n",
    "        torch.onnx.export(model, xin, onnx_f, input_names=['input'], output_names=['output'])\n",
    "        network = Marabou.read_onnx(onnx_f)\n",
    "        \n",
    "        out_vars = network.outputVars[0].flatten()\n",
    "        \n",
    "        out_constraints = []\n",
    "        for i in range(out_vars.shape[0]):\n",
    "            constraint = MarabouCore.Equation(MarabouCore.Equation.GE)\n",
    "            for j in range(out_vars.shape[0]):\n",
    "                if i != j:\n",
    "                    constraint.addAddend(1, out_vars[j])\n",
    "            constraint.addAddend(-1, out_vars[i])\n",
    "            constraint.setScalar(0)\n",
    "            out_constraints.append(constraint)\n",
    "        \n",
    "        options = Marabou.createOptions(verbosity=0)\n",
    "        exit_code, vals, stats = network.solve(options=options)\n",
    "        \n",
    "        if exit_code == \"sat\":\n",
    "            softmax_vals = torch.exp(torch.tensor(vals[out_vars[0][0]:], dtype=torch.float32))\n",
    "            softmax_vals /= torch.sum(softmax_vals)\n",
    "            results.append(torch.max(softmax_vals).item() <= tau)\n",
    "        else:\n",
    "            results.append(True)\n",
    "    \n",
    "    return np.mean(results)\n",
    "\n",
    "def verify_robustness(model, X, epsilon, tau, f):\n",
    "    results = []\n",
    "    for x in X:\n",
    "        xin = torch.tensor(x, dtype=torch.float32).unsqueeze(0)\n",
    "        onnx_f = \"model.onnx\"\n",
    "        torch.onnx.export(model, xin, onnx_f, input_names=['input'], output_names=['output'])\n",
    "        network = Marabou.read_onnx(onnx_f)\n",
    "        \n",
    "        in_vars = network.inputVars[0]\n",
    "        out_vars = network.outputVars[0].flatten()\n",
    "        \n",
    "        in_query = MarabouCore.InputQuery()\n",
    "        in_query.setNumberOfVariables(len(in_vars))\n",
    "        \n",
    "        for i in range(in_vars.shape[0]):\n",
    "            in_query.setLowerBound(in_vars[i][0], x[i] - epsilon)\n",
    "            in_query.setUpperBound(in_vars[i][0], x[i] + epsilon)\n",
    "        \n",
    "        out_constraints = []\n",
    "        for i in range(out_vars.shape[0]):\n",
    "            constraint = MarabouCore.Equation(MarabouCore.Equation.GE)\n",
    "            for j in range(out_vars.shape[0]):\n",
    "                if i != j:\n",
    "                    constraint.addAddend(1, out_vars[j])\n",
    "            constraint.addAddend(-1, out_vars[i])\n",
    "            constraint.setScalar(0)\n",
    "            out_constraints.append(constraint)\n",
    "        \n",
    "        options = Marabou.createOptions(verbosity=0)\n",
    "        exit_code, vals, stats = network.solve(in_query, out_constraints, options)\n",
    "        \n",
    "        if exit_code == \"sat\":\n",
    "            softmax_vals = torch.exp(torch.tensor(vals[out_vars[0][0]:], dtype=torch.float32))\n",
    "            softmax_vals /= torch.sum(softmax_vals)\n",
    "            results.append(torch.max(softmax_vals).item() >= tau)\n",
    "        else:\n",
    "            results.append(True)\n",
    "    \n",
    "    return np.mean(results)\n",
    "\n",
    "def verify_monotonicity(model, X1, X2, X_ID, f):\n",
    "    results = []\n",
    "    for x1, x2 in zip(X1, X2):\n",
    "        d1 = np.min(np.linalg.norm(X_ID - x1, axis=1))\n",
    "        d2 = np.min(np.linalg.norm(X_ID - x2, axis=1))\n",
    "\n",
    "        if d1 <= d2:\n",
    "            results.append(True)\n",
    "            continue\n",
    "\n",
    "        xin1 = torch.tensor(x1, dtype=torch.float32).unsqueeze(0)\n",
    "        xin2 = torch.tensor(x2, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        onnx_f = \"model.onnx\"\n",
    "        torch.onnx.export(model, xin1, onnx_f, input_names=['input'], output_names=['output'])\n",
    "        network = Marabou.read_onnx(onnx_f)\n",
    "\n",
    "        out_vars1 = network.outputVars[0].flatten()\n",
    "        out_vars2 = network.outputVars[0].flatten()\n",
    "\n",
    "        out_constraint = MarabouCore.Equation(MarabouCore.Equation.GE)\n",
    "        for i in range(out_vars1.shape[0]):\n",
    "            out_constraint.addAddend(1, out_vars1[i])\n",
    "            out_constraint.addAddend(-1, out_vars2[i])\n",
    "        out_constraint.setScalar(0)\n",
    "\n",
    "        options = Marabou.createOptions(verbosity=0)\n",
    "        exit_code, vals, stats = network.solve(options=options)\n",
    "\n",
    "        results.append(exit_code == \"unsat\")\n",
    "\n",
    "    return np.mean(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c6e7bf-4f39-439e-967a-9f715b0b4d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "n_ood = 5\n",
    "n_robust = 5\n",
    "n_mono = 5\n",
    "tau=0.8\n",
    "epsilon=0.5\n",
    "\n",
    "results = []\n",
    "\n",
    "for lam, model in models.items():\n",
    "    # OOD rejection\n",
    "    with open(f\"ood_rejection_lambda_{lam}.txt\", \"w\") as f:\n",
    "        X_OOD_subset = test_outliers[:n_ood]\n",
    "        ood_rejection_rate = verify_ood_rejection(model, X_OOD_subset, tau, f)\n",
    "\n",
    "    # robustness\n",
    "    with open(f\"robustness_lambda_{lam}.txt\", \"w\") as f:\n",
    "        X_robust_subset = X_test[:n_robust]\n",
    "        robustness_rate = verify_robustness(model, X_robust_subset, epsilon, tau, f)\n",
    "\n",
    "    # monotonicity\n",
    "    with open(f\"monotonicity_lambda_{lam}.txt\", \"w\") as f:\n",
    "        X_mono_subset1 = X_test[:n_mono]\n",
    "        X_mono_subset2 = X_test[n_mono:2*n_mono]\n",
    "        monotonicity_rate = verify_monotonicity(model, X_mono_subset1, X_mono_subset2, X_train, f)\n",
    "\n",
    "    results.append((lam, ood_rejection_rate, robustness_rate, monotonicity_rate))\n",
    "\n",
    "table = PrettyTable()\n",
    "table.field_names = [\"Lambda\", \"OOD rejection rate\", \"Robustness rate\", \"Monotonicity rate\"]\n",
    "for result in results:\n",
    "    table.add_row(result)\n",
    "\n",
    "print(\"Results:\")\n",
    "print(table)\n",
    "\n",
    "lambdas = [result[0] for result in results]\n",
    "ood_rejection_rates = [result[1] for result in results]\n",
    "robustness_rates = [result[2] for result in results]\n",
    "monotonicity_rates = [result[3] for result in results]\n",
    "\n",
    "plt.figure(figsize=(24, 6))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(lambdas, ood_rejection_rates, marker='o')\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('OOD rejection rate')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(lambdas, robustness_rates, marker='s')\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Robustness rate')\n",
    "\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(lambdas, monotonicity_rates, marker='^')\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Monotonicity rate')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0957d84-519d-4a2f-b5b6-10ce6e341f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9e0c8d-9ce7-4df0-998b-fa810c60a682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e05d9a-a339-4a84-b7de-4bfa63f3bfb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b236075-92fa-4933-ba66-4aa20a68d727",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
